{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5029260,"sourceType":"datasetVersion","datasetId":2918585}],"dockerImageVersionId":30512,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Model & Method","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch\nfrom torch.autograd import Function\nimport torch.nn.functional as F\nfrom torch.functional import tensordot\nimport numpy as np\n\n# ========== 新增交叉注意力模块 ==========\nclass CrossAttention(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        self.query = nn.Linear(dim, dim)\n        self.key = nn.Linear(dim, dim)\n        self.value = nn.Linear(dim, dim)\n        self.scale = dim ** -0.5\n\n    def forward(self, x1, x2):\n        q = self.query(x1)\n        k = self.key(x2)\n        v = self.value(x2)\n        attn = torch.matmul(q, k.transpose(-2, -1)) * self.scale\n        attn = F.softmax(attn, dim=-1)\n        out = torch.matmul(attn, v)\n        return out + x1  # 残差连接\n\n\nclass CNN(nn.Module):\n    def __init__(self, configs):\n        super(CNN, self).__init__()\n        self.modality_num = configs.modality_nums  # 模态数\n        configs = configs.model_configs['CNN']\n\n        self.conv1_blocks = nn.ModuleList([nn.Sequential(\n            nn.Conv1d(configs.input_channels, configs.mid_channels, kernel_size=configs.kernel_size,\n                      stride=configs.stride, bias=False, padding=(configs.kernel_size // 2)),\n            nn.BatchNorm1d(configs.mid_channels),\n            nn.ReLU(),\n            nn.MaxPool1d(kernel_size=2, stride=2, padding=1),\n            nn.Dropout(configs.dropout)\n        ) for i in range(self.modality_num)])\n\n        self.conv2_blocks = nn.ModuleList([nn.Sequential(\n            nn.Conv1d(configs.mid_channels, configs.mid_channels * 2,\n                      kernel_size=8, stride=1, bias=False, padding=4),\n            nn.BatchNorm1d(configs.mid_channels * 2),\n            nn.ReLU(),\n            nn.MaxPool1d(kernel_size=2, stride=2, padding=1)\n        ) for i in range(self.modality_num)])\n\n        self.conv3_blocks = nn.ModuleList([nn.Sequential(\n            nn.Conv1d(configs.mid_channels * 2, configs.final_out_channels, kernel_size=8, stride=1, bias=False,\n                      padding=4),\n            nn.BatchNorm1d(configs.final_out_channels),\n            nn.ReLU(),\n            nn.MaxPool1d(kernel_size=2, stride=2, padding=1),\n        ) for i in range(self.modality_num)])\n\n        self.adaptive_pools = nn.ModuleList([nn.AdaptiveAvgPool1d(\n            configs.features_len) for i in range(self.modality_num)])\n\n    def forward(self, k_x_in):\n        '''x: [k*(N, 3, 300)]\n            系列卷积不论dim=-1为多少，128，200，300输出都是128\n        '''\n        k_out = []\n        for modality_idx in range(self.modality_num):\n            x = k_x_in[modality_idx]\n            x = self.conv1_blocks[modality_idx](x)\n            # print(f\"conv1 x_out: {x.shape}\")\n            x = self.conv2_blocks[modality_idx](x)\n            # print(f\"conv2 x_out: {x.shape}\")\n            x = self.conv3_blocks[modality_idx](x)\n            # print(f\"conv3 x_out: {x.shape}\")\n            x = self.adaptive_pools[modality_idx](x)\n            # print(f\"adaptive x_out: {x.shape}\")\n            x_flat = x.reshape(x.shape[0], 1, -1)\n            # print(f\"sensor conv flat: {x_flat.shape}\")  # (N, 1, 128)\n            k_out.append(x_flat)\n\n        k_out = torch.cat(k_out, dim=1)\n        # print(f\"conv sensors cat: {k_out.shape}\")  # (N, k, 128)\n        # print(f\"conv out: {k_out.shape}\")  # (N, k, 128)\n        return k_out\n\n\nclass c_fusion(nn.Module):\n    def __init__(self, configs) -> None:\n        super(c_fusion, self).__init__()\n        self.modality_num = configs.modality_nums\n        self.fusion_cfg = configs.model_configs['fusion']\n        self.d_W1 = nn.Parameter(torch.normal(\n            mean=0, std=0.1, size=[self.fusion_cfg.final_out_channels, 1], requires_grad=True))\n        self.d_b1 = nn.Parameter(torch.normal(mean=0, std=0.1, size=[\n                                 1, self.modality_num, 1]), requires_grad=True)  # (1, k, 1)\n        self.d_w1 = nn.Parameter(torch.normal(\n            mean=0, std=0.1, size=[self.modality_num, 1]), requires_grad=True)\n\n    def forward(self, x):\n        '''x: (N, k, len)'''\n        # print(f\"attn x_unsqueeze: {x.shape}\")  # (N, k, 128)\n\n        MLP_input = tensordot(x, self.d_W1, dims=1)\n        MLP_input += self.d_b1\n        # print(f\"MLP input: {MLP_input.shape}\")\n        miu = torch.tanh(MLP_input)  # [BN, k, 1]\n        softmax_input = tensordot(miu, self.d_w1, dims=1)\n        # print(f\"softmax_input: {softmax_input.shape}\")\n        alpha = F.softmax(softmax_input, dim=1)  # [BN, k, 1]\n        f_per_sensor = alpha * x  # [BN, 1, 64]\n        # print(f\"f_modality: {f_per_sensor.shape}\")\n        out = torch.sum(f_per_sensor, dim=1)  # [BN, len]\n        # print(f\"c_fusion: {out.shape}\")\n        return out\n\n\nclass FE(nn.Module):\n    def __init__(self, configs) -> None:\n        '''input:\n                x_k_t: [k*(N, 3, 300)]\n                x_k_f: [k*(N, 3, 151)]\n            return:\n                merge_tf: (N, 2*128)'''\n        super(FE, self).__init__()\n        self.cnn_t = CNN(configs=configs)\n        self.fusion_t = c_fusion(configs=configs)\n        self.cnn_f = CNN(configs=configs)\n        self.fusion_f = c_fusion(configs=configs)\n        # ========== 新增模块 ==========\n        self.cross_attention_t = CrossAttention(128)  # 时域交叉注意力\n        self.cross_attention_f = CrossAttention(128)  # 频域交叉注意力\n        # self.contrastive_proj = nn.Sequential(        # 对比学习投影层\n        #     nn.Linear(128, 128),\n        #     nn.ReLU(),\n        #     nn.Linear(128, 64)\n        # )\n        \n    def forward(self, x_k_t, x_k_f):\n        x_k_t = self.cnn_t(x_k_t)\n        merge_t = self.fusion_t(x_k_t)  # (N, 300)\n\n        x_k_f = self.cnn_f(x_k_f)  # (N, k, 151)\n        merge_f = self.fusion_f(x_k_f)\n\n        # print(x_k_f.shape)  # (N, k, 151)\n        # print(merge_f.shape)  # (N, 128)\n\n        # ========== 新增交叉交互 ==========\n        merge_t = self.cross_attention_t(merge_t, merge_f)  # 时域融合频域信息\n        merge_f = self.cross_attention_f(merge_f, merge_t)  # 频域融合时域信息\n        \n        # 合并时频特征\n        merge_tf = torch.cat([merge_t, merge_f], dim=1)\n        return merge_tf, merge_t, merge_f  # 返回三个特征用于对比学习\n\n\nclass Classifier(nn.Module):\n    def __init__(self, configs):\n        super(Classifier, self).__init__()\n        label_num = configs.num_classes\n        configs = configs.model_configs['Classifier']\n        model_output_dim = configs.features_len\n        self.hidden_dim = configs.hidden_dim\n        self.logits = nn.Sequential(\n            nn.Linear(model_output_dim * configs.final_out_channels * 2, self.hidden_dim * 2),  # 2 为 temporal + frequency\n            nn.ReLU(),\n            nn.Linear(self.hidden_dim * 2, self.hidden_dim),\n            nn.ReLU(),\n            nn.Linear(self.hidden_dim, label_num),\n            nn.LogSoftmax(dim=-1),\n        )\n\n    def forward(self, x_in):\n        '''x: (N, 2*128)'''\n        # print(f\"Codats_Classifier x_in: {x_in.shape}\")\n        predictions = self.logits(x_in)\n        return predictions\n\n\nclass Discriminator(nn.Module):\n    def __init__(self, configs):\n        \"\"\"Init discriminator.\"\"\"\n        super(Discriminator, self).__init__()\n        configs = configs.model_configs['Discriminator']\n        self.layer = nn.Sequential(\n            nn.Linear(configs.features_len * configs.final_out_channels * 2,\n                      configs.disc_hid_dim * 2),  # 2 为 temporal + frequency\n            nn.ReLU(),\n            nn.Linear(configs.disc_hid_dim * 2, configs.disc_hid_dim),\n            nn.ReLU(),\n            nn.Linear(configs.disc_hid_dim, 2),\n            nn.LogSoftmax(dim=1),\n        )\n\n    def forward(self, input):\n        \"\"\"Forward the discriminator.\n            x: (N, k*len)\"\"\"\n        out = self.layer(input)\n        return out\n\n\nclass ReverseLayerF(Function):\n    @staticmethod\n    def forward(ctx, x, alpha):\n        ctx.alpha = alpha\n        return x.view_as(x)\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        output = grad_output.neg() * ctx.alpha\n        return output, None\n\n\n\n\n\n\nclass ATFA(nn.Module):\n    \"\"\"\n    CoDATS: https://arxiv.org/pdf/2005.10996.pdf\n    \"\"\"\n\n    def __init__(self, configs, hparams, device):\n        super(ATFA, self).__init__()\n        self.configs = configs\n        self.cross_entropy = nn.CrossEntropyLoss()\n        self.channel_num = configs.channel_nums  # 不同模态的通道数e.g. [3,3,1]\n        self.feature_extractor = FE(configs=configs)\n        self.classifier_tf = Classifier(configs)\n        self.domain_discriminator_tf = Discriminator(configs)\n\n        self.optimizer = torch.optim.Adam(\n            list(self.feature_extractor.parameters()) +\n            list(self.classifier_tf.parameters()),\n            lr=hparams[\"learning_rate\"],\n            weight_decay=hparams[\"weight_decay\"], betas=(0.5, 0.99)\n        )\n        self.optimizer_disc = torch.optim.Adam(\n            self.domain_discriminator_tf.parameters(),\n            lr=hparams[\"learning_rate\"],\n            weight_decay=hparams[\"weight_decay\"], betas=(0.5, 0.99)\n        )\n        self.hparams = hparams\n        self.device = device\n\n    def get_f_x(self, x):\n        x_f = torch.fft.rfft(x)\n        return x_f.real\n\n    # def update(self, src_x, src_y, trg_x, step, epoch, len_dataloader):\n    #     '''x: (N, 6, 128)\n    #         y: (N,)'''\n    #     p = float(step + epoch * len_dataloader) / \\\n    #         self.hparams[\"num_epochs\"] + 1 / len_dataloader\n    #     alpha = 2. / (1. + np.exp(-10 * p)) - 1\n\n    #     # split_modality_x\n    #     modality_src_x_t = torch.split(\n    #         src_x, split_size_or_sections=self.channel_num, dim=1)\n    #     modality_trg_x_t = torch.split(\n    #         trg_x, split_size_or_sections=self.channel_num, dim=1)\n\n    #     # get t/f x\n    #     # src_x_t = src_x\n    #     modality_src_x_f = [self.get_f_x(src_x_t)\n    #                         for src_x_t in modality_src_x_t]\n    #     # trg_x_t = trg_x\n    #     modality_trg_x_f = [self.get_f_x(trg_x_t)\n    #                         for trg_x_t in modality_trg_x_t]\n\n    #     # zero grad\n    #     self.optimizer.zero_grad()\n    #     self.optimizer_disc.zero_grad()\n\n    #     # domain label\n    #     domain_label_src = torch.ones(len(src_x)).to(self.device)\n    #     domain_label_trg = torch.zeros(len(trg_x)).to(self.device)\n\n    #     # src features\n    #     src_feat_tf = self.feature_extractor(\n    #         modality_src_x_t, modality_src_x_f)\n    #     src_pred = self.classifier_tf(src_feat_tf)\n\n    #     # trg features\n    #     trg_feat_tf = self.feature_extractor(\n    #         modality_trg_x_t, modality_trg_x_f)\n\n    #     # Task classification  Loss\n    #     src_cls_loss = self.cross_entropy(src_pred.squeeze(), src_y)\n\n    #     # Domain classification loss\n    #     # source\n    #     src_feat_reversed = ReverseLayerF.apply(src_feat_tf, alpha)\n    #     src_domain_pred = self.domain_discriminator_tf(src_feat_reversed)\n    #     src_domain_loss = self.cross_entropy(\n    #         src_domain_pred, domain_label_src.long())\n\n    #     # target\n    #     trg_feat_reversed = ReverseLayerF.apply(trg_feat_tf, alpha)\n    #     trg_domain_pred = self.domain_discriminator_tf(trg_feat_reversed)\n    #     trg_domain_loss = self.cross_entropy(\n    #         trg_domain_pred, domain_label_trg.long())\n\n    #     # Total domain loss\n    #     domain_loss = src_domain_loss + trg_domain_loss\n\n    #     loss = self.hparams[\"src_cls_loss_wt\"] * src_cls_loss + \\\n    #         self.hparams[\"domain_loss_wt\"] * domain_loss\n\n    #     loss.backward()\n    #     self.optimizer.step()\n    #     self.optimizer_disc.step()\n\n    #     return {'Total_loss': loss.item(), 'Domain_loss': domain_loss.item(), 'Src_cls_loss': src_cls_loss.item()}\n    def update(self, src_x, src_y, trg_x, step, epoch, len_dataloader):\n        '''x: (N, 6, 128)\n            y: (N,)'''\n        p = float(step + epoch * len_dataloader) / \\\n            self.hparams[\"num_epochs\"] + 1 / len_dataloader\n        alpha = 2. / (1. + np.exp(-10 * p)) - 1\n    \n        # split_modality_x ------------------------------------------------------\n        modality_src_x_t = torch.split(src_x, split_size_or_sections=self.channel_num, dim=1)\n        modality_trg_x_t = torch.split(trg_x, split_size_or_sections=self.channel_num, dim=1)\n    \n        # get t/f x -------------------------------------------------------------\n        modality_src_x_f = [self.get_f_x(src_x_t) for src_x_t in modality_src_x_t]\n        modality_trg_x_f = [self.get_f_x(trg_x_t) for trg_x_t in modality_trg_x_t]\n    \n        # zero grad -------------------------------------------------------------\n        self.optimizer.zero_grad()\n        self.optimizer_disc.zero_grad()\n    \n        # domain label ----------------------------------------------------------\n        domain_label_src = torch.ones(len(src_x)).to(self.device)\n        domain_label_trg = torch.zeros(len(trg_x)).to(self.device)\n    \n        # ========== 核心修改点 ==========\n        # src features ----------------------------------------------------------\n        src_feat_tf, src_t, src_f = self.feature_extractor(modality_src_x_t, modality_src_x_f)  # 修改点1：获取时频单独特征\n        src_pred = self.classifier_tf(src_feat_tf)\n    \n        # trg features ----------------------------------------------------------\n        trg_feat_tf, trg_t, trg_f = self.feature_extractor(modality_trg_x_t, modality_trg_x_f)\n    \n        # # ========== 新增对比损失计算 ==========\n        # src_proj_t = self.feature_extractor.contrastive_proj(src_t)  # 修改点2：投影时域特征\n        # src_proj_f = self.feature_extractor.contrastive_proj(src_f)  # 修改点3：投影频域特征\n        # contrastive_loss = self.nt_xent_loss(src_proj_t, src_proj_f)  # 修改点4：计算对比损失\n    \n        # Task classification Loss ----------------------------------------------\n        src_cls_loss = self.cross_entropy(src_pred.squeeze(), src_y)\n    \n        # Domain classification loss --------------------------------------------\n        # source\n        src_feat_reversed = ReverseLayerF.apply(src_feat_tf, alpha)\n        src_domain_pred = self.domain_discriminator_tf(src_feat_reversed)\n        src_domain_loss = self.cross_entropy(src_domain_pred, domain_label_src.long())\n    \n        # target\n        trg_feat_reversed = ReverseLayerF.apply(trg_feat_tf, alpha)\n        trg_domain_pred = self.domain_discriminator_tf(trg_feat_reversed)\n        trg_domain_loss = self.cross_entropy(trg_domain_pred, domain_label_trg.long())\n    \n        # Total domain loss -----------------------------------------------------\n        domain_loss = src_domain_loss + trg_domain_loss\n    \n        # ========== 修改总损失公式 ==========\n        # loss = (\n        #     self.hparams[\"src_cls_loss_wt\"] * src_cls_loss \n        #     + self.hparams[\"domain_loss_wt\"] * domain_loss\n        #     + self.hparams[\"contrastive_loss_wt\"] * contrastive_loss  # 修改点5：添加加权对比损失\n        # )\n\n                # 总损失公式\n        loss = (\n            self.hparams[\"src_cls_loss_wt\"] * src_cls_loss \n            + self.hparams[\"domain_loss_wt\"] * domain_loss\n        )\n        \n        # Backpropagation -------------------------------------------------------\n        loss.backward()\n        self.optimizer.step()\n        self.optimizer_disc.step()\n    \n        return {'Total_loss': loss.item(), 'Domain_loss': domain_loss.item(), 'Src_cls_loss': src_cls_loss.item()}\n\n    def test_batch(self, trg_x):\n        modality_trg_x_t = torch.split(\n            trg_x, split_size_or_sections=self.channel_num, dim=1)\n        modality_trg_x_f = [self.get_f_x(trg_x_t)\n                            for trg_x_t in modality_trg_x_t]\n\n        # 关键修复：解包返回值的三个元素，只取第一个\n        trg_feat_tf, _, _ = self.feature_extractor(modality_trg_x_t, modality_trg_x_f)\n\n        trg_pred = self.classifier_tf(trg_feat_tf)\n        return trg_pred\n    # ========== 新增对比损失函数 ==========\n    def nt_xent_loss(self, z1, z2, temperature=0.07):\n        batch_size = z1.size(0)\n        z = torch.cat([z1, z2], dim=0)\n        z = F.normalize(z, dim=1)\n        sim_matrix = torch.mm(z, z.T) / temperature\n        mask = torch.eye(2*batch_size, device=z.device).bool()\n        sim_matrix = sim_matrix.masked_fill(mask, -1e12)\n        labels = torch.arange(2*batch_size, device=z.device)\n        labels = (labels + batch_size) % (2*batch_size)\n        return F.cross_entropy(sim_matrix, labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:04:44.299848Z","iopub.execute_input":"2025-05-03T13:04:44.300226Z","iopub.status.idle":"2025-05-03T13:04:44.340952Z","shell.execute_reply.started":"2025-05-03T13:04:44.300178Z","shell.execute_reply":"2025-05-03T13:04:44.339911Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Data & Utils","metadata":{}},{"cell_type":"code","source":"import wandb\nfrom kaggle_secrets import UserSecretsClient\nfrom sklearn.metrics import classification_report, accuracy_score\nimport pandas as pd\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms\n\nfrom sklearn.model_selection import train_test_split\n\nimport os\nimport numpy as np\nimport random\n\n\ndef split_valid(dataset):\n    data = dataset[\"samples\"]\n    label = dataset[\"labels\"]\n    train_data, valid_data, train_labels, valid_labels = train_test_split(\n        data, label, test_size=0.25, shuffle=True, random_state=42)\n    train_dataset = {\n        \"samples\": train_data,\n        \"labels\": train_labels,\n    }\n    valid_dataset = {\n        \"samples\": valid_data,\n        \"labels\": valid_labels,\n    }\n    return train_dataset, valid_dataset\n\n\nclass Load_Dataset(Dataset):\n    def __init__(self, dataset, normalize):\n        super(Load_Dataset, self).__init__()\n\n        data = dataset[\"samples\"]\n        label = dataset[\"labels\"]\n\n        if len(data.shape) < 3:\n            data = data.unsqueeze(2)\n\n        if isinstance(data, np.ndarray):\n            data = torch.from_numpy(data)\n            label = torch.from_numpy(label).long()\n\n        # make sure the Channels in second dim\n        if data.shape.index(min(data.shape[1], data.shape[2])) != 1:\n            # 数最小（channel）的dim不是1，要将channel转换到dim1来\n            data = data.permute(0, 2, 1)  # (N, 128, 6)=>(N, 6, 128)\n\n        self.data = data\n        self.label = label\n\n        self.num_channels = data.shape[1]\n\n        if normalize:\n            # Assume datashape: num_samples, num_channels, seq_length\n            data_mean = torch.FloatTensor(self.num_channels).fill_(\n                0).tolist()  # assume min= number of channels\n            data_std = torch.FloatTensor(self.num_channels).fill_(\n                1).tolist()  # assume min= number of channels\n            data_transform = transforms.Normalize(mean=data_mean, std=data_std)\n            self.transform = data_transform\n        else:\n            self.transform = None\n\n        self.len = data.shape[0]\n\n    def __getitem__(self, index):\n        if self.transform is not None:\n            output = self.transform(\n                self.data[index].view(self.num_channels, -1, 1))\n            self.data[index] = output.view(self.data[index].shape)\n\n        return self.data[index].float(), self.label[index].long()\n\n    def __len__(self):\n        return self.len\n\n\ndef data_generator(data_path, domain_id, dataset_configs, hparams):\n    \"\"\"\n        Args:\n            data_path      : 数据文件夹位置\n            domain_id      : 用户的id\n            dataset_configs: 数据集配置\n            hparams        : 超参数配置\n    \"\"\"\n    # loading path\n    train_dataset = torch.load(os.path.join(\n        data_path, \"train_\" + str(domain_id) + \".pt\"))\n    test_dataset = torch.load(os.path.join(\n        data_path, \"test_\" + str(domain_id) + \".pt\"))\n    train_dataset, valid_dataset = split_valid(train_dataset)\n\n    # Loading datasets\n    train_dataset = Load_Dataset(train_dataset, dataset_configs.normalize)\n    valid_dataset = Load_Dataset(valid_dataset, dataset_configs.normalize)\n    test_dataset = Load_Dataset(test_dataset, dataset_configs.normalize)\n\n    # Dataloaders\n    batch_size = hparams[\"batch_size\"]\n    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size,\n                              shuffle=True, drop_last=True, num_workers=2)\n    valid_loader = DataLoader(dataset=valid_dataset, batch_size=batch_size,\n                              shuffle=True, drop_last=True, num_workers=2)\n\n    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size,\n                             shuffle=False, drop_last=dataset_configs.drop_last, num_workers=2)\n    return train_loader, valid_loader, test_loader\n\n\ndef fix_randomness(SEED):\n    random.seed(SEED)\n    np.random.seed(SEED)\n    torch.manual_seed(SEED)\n    torch.cuda.manual_seed(SEED)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n\n\"\"\"\n  一个epoch内，记录不同batch的测试指标，并返回平均值\n\"\"\"\n\n\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        \"\"\"n是batch增加的个数\"\"\"\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef _calc_metrics(pred_labels, true_labels, target_names):\n    \"\"\"\n        在log_dir下保存.csv，记录衡量指标，返回百分制的acc和maf1\n    \"\"\"\n    # print(pred_labels.shape)\n    pred_labels = np.array(pred_labels).astype(int)\n    true_labels = np.array(true_labels).astype(int)\n\n    # precisiion, recall, f1, support\n    r = classification_report(\n        true_labels, pred_labels, labels=range(len(target_names)), target_names=target_names, digits=6, output_dict=True)\n    df = pd.DataFrame(r)\n\n    # acc\n    accuracy = accuracy_score(true_labels, pred_labels)\n    df[\"accuracy\"] = accuracy  # 一列都是重复的值，没有办法\n\n    # 转换为百分制\n    df = df * 100\n\n    # 保存结果\n#     file_name = \"classification_report.csv\"\n#     report_Save_path = os.path.join(log_dir, file_name)\n#     df.to_csv(report_Save_path)\n#     df.to_excel(report_Save_path+\".xlsx\")\n\n    return accuracy * 100, r[\"macro avg\"][\"f1-score\"] * 100\n\n\nclass EarlyStopping:\n    def __init__(self, patience=7, verbose=True, delta=0):\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n\n    def __call__(self, val_loss, model=None, path=None):\n        score = -val_loss\n        if self.best_score is None:\n            self.best_score = score\n            print(\n                f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).\\n')\n            self.val_loss_min = val_loss\n        elif score <= self.best_score + self.delta:\n            self.counter += 1\n            print(\n                f'EarlyStopping counter: {self.counter} out of {self.patience}\\n')\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.counter = 0\n\n    def refresh(self):\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n\n\nuser_secrets = UserSecretsClient()\n\n# I have saved my API token with \"wandb_api\" as Label.\n# If you use some other Label make sure to change the same below.\nwandb_api = user_secrets.get_secret(\n    \"wandb_api\")  # Add-ons => Secrets 选中 keys 才能用\n\nwandb.login(key=wandb_api)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:04:44.343105Z","iopub.execute_input":"2025-05-03T13:04:44.343538Z","iopub.status.idle":"2025-05-03T13:04:44.640160Z","shell.execute_reply.started":"2025-05-03T13:04:44.343506Z","shell.execute_reply":"2025-05-03T13:04:44.639148Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Trainer","metadata":{}},{"cell_type":"code","source":"import collections\nfrom tqdm import tqdm\nimport torch\nimport os\nimport numpy as np\nimport torch.nn.functional as F\nimport pandas as pd\nimport wandb\n\n\nclass trainer():\n    def __init__(self, args) -> None:\n        self.method_cls = args.method_cls\n        self.data_path = args.data_path\n        self.ds_config = args.ds_configs\n        self.hparams = args.hparams\n        self.method_name = args.method_name\n        self.dataset_name = args.dataset_name\n        self.default_hparams = {\n            **self.hparams.alg_hparams[self.method_name],\n            **self.hparams.train_params,\n        }\n        self.es = EarlyStopping()\n        self.num_runs = args.num_runs  # 每个任务重复次数（不同seed）\n        self.device = torch.device(args.device)\n        # 记录结果\n\n    def get_dataloader(self, uid):\n        \"\"\"\n            trian_dl, valid_dl, test_dl\n        \"\"\"\n        return data_generator(self.data_path, uid, self.ds_config, self.default_hparams)\n\n    def evaluate(self, valid=False):\n        \"\"\"\n            验证模型性能\n            \n            return:\n                metric: {'accuracy': str, 'maf1_score': str}\n                loss: str\n        \"\"\"\n        method = self.method.to(self.device).eval()\n\n        total_loss_ = []\n\n        self.trg_pred_labels = []\n        self.trg_true_labels = []\n\n        if valid:\n            dataloader = self.trg_valid_dl\n        else:\n            dataloader = self.trg_test_dl\n\n        with torch.no_grad():\n            for data, labels in dataloader:\n                data = data.float().to(self.device)\n                labels = labels.view((-1)).long().to(self.device)\n\n                # forward pass\n                predictions = method.test_batch(trg_x=data)\n\n                # compute loss\n                loss = F.cross_entropy(predictions, labels)\n                total_loss_.append(loss.item())\n                # get the index of the max log-probability\n                pred = predictions.detach().argmax(dim=1)\n\n                self.trg_pred_labels.append(pred.cpu())\n                self.trg_true_labels.append(labels.cpu())\n\n        self.trg_loss = torch.tensor(total_loss_).mean()  # average loss\n\n        # n*[BN,]->[n*BN]\n        self.trg_pred_labels = torch.concat(self.trg_pred_labels, dim=0)\n        self.trg_true_labels = torch.concat(self.trg_true_labels, dim=0)\n\n        # 计算结果\n        self.acc, self.maf1 = _calc_metrics(self.trg_pred_labels, self.trg_true_labels,\n                                            self.ds_config.class_names)\n\n        self.run_metrics = {'accuracy': self.acc, 'maf1_score': self.maf1}\n\n        return self.run_metrics, self.trg_loss\n\n    def save_results(self):\n        \"\"\"\n            将运行结果汇总生成csv，保存在实验目录下（scenario的上一层）\n                            acc,    maf1\n            scenario_run\n        \"\"\"\n        self.all_scenario_results = {\n            \"acc\": {},\n            \"maf1\": {}\n        }\n        for run_name in self.metrics.keys():\n            self.all_scenario_results[\"acc\"][run_name] = self.metrics[run_name]['accuracy']\n            self.all_scenario_results[\"maf1\"][run_name] = self.metrics[run_name]['maf1_score']\n\n        # all_run_accs = np.array(self.metrics['accuracy'])\n        # all_run_maf1s = np.array(self.metrics['maf1_score'])\n\n        # acc_mean = all_run_accs.mean()\n        # acc_std = all_run_accs.std()\n\n        # maf1_mean = all_run_maf1s.mean()\n        # maf1_std = all_run_maf1s.std()\n\n        # self.all_scenario_results[\"acc_mean\"][self.tmp_scenario] = acc_mean\n        # self.all_scenario_results[\"acc_std\"][self.tmp_scenario] = acc_std\n        # self.all_scenario_results[\"maf1_mean\"][self.tmp_scenario] = maf1_mean\n        # self.all_scenario_results[\"maf1_std\"][self.tmp_scenario] = maf1_std\n\n        # 所有scenario_run结果，保存在Exp_logs/Exp_name/exp_id下\n        self.rs_df = pd.DataFrame(self.all_scenario_results)\n        file_save_pth = os.path.join(\n            \"/kaggle/working/\", f\"{self.dataset_name}_{self.method_name}_all_scenario_run_results.csv\")\n        self.rs_df.to_csv(file_save_pth)\n        return\n\n    def train(self):\n        scenarios = self.ds_config.scenarios\n        self.metrics = {}\n        for i in scenarios:\n            self.tmp_scenario = f\"{i[0]}_to_{i[1]}\"\n            src_id = i[0]\n            trg_id = i[1]\n\n            # 获取dataloader\n            print(f'-----获取dataloader-----')\n            self.src_train_dl, self.src_valid_dl, self.src_test_dl = self.get_dataloader(\n                src_id)\n            self.trg_train_dl, self.trg_valid_dl, self.trg_test_dl = self.get_dataloader(\n                trg_id)\n\n            log_flag = True\n\n            for run_id in range(self.num_runs):\n                seed = run_id\n                if log_flag == True:\n                    # 每个scenario只记录一次run（看收敛）\n                    self.run = wandb.init(project='UDA',\n                                          #                                  group='AdvSKM',\n                                          tags=[\n                                              f'seed_{seed}', self.tmp_scenario, self.dataset_name, self.method_name],\n                                          #                                  job_type='train',\n                                          reinit=True,\n                                          )\n\n                # 固定随机种子\n                fix_randomness(seed)\n\n                # 类实例化\n                method = self.method_cls(\n                    configs=self.ds_config, hparams=self.default_hparams, device=self.device).to(self.device)\n\n                # AvgMeters\n                avg_meters = collections.defaultdict(lambda: AverageMeter())\n\n                # 训练\n                for epoch in range(1, self.default_hparams[\"num_epochs\"]+1):\n\n                    joint_loaders = enumerate(\n                        zip(self.src_train_dl, self.trg_train_dl))\n                    len_dataloader = min(\n                        len(self.src_train_dl), len(self.trg_train_dl))\n\n                    method.train()\n                    for step, ((src_x, src_y), (trg_x, _)) in tqdm(joint_loaders):\n                        src_x, src_y, trg_x = src_x.float().to(self.device), src_y.long().to(\n                            self.device), trg_x.float().to(self.device)\n\n                        if self.method_name == \"CoDATS\" or self.method_name == 'CoDATS_tf' or self.method_name == 'ATFA':\n                            loss_dict = method.update(\n                                src_x=src_x, src_y=src_y, trg_x=trg_x, step=step, epoch=epoch, len_dataloader=len_dataloader)\n                        else:\n                            loss_dict = method.update(src_x, src_y, trg_x)\n\n                        for key, val in loss_dict.items():\n                            # batch loss，n=1\n                            avg_meters[f\"Loss/{key}\"].update(val, n=1)\n\n                    # 每个epoch输出结果\n                    print(\n                        f'------------ train epoch: {epoch} ------------------')\n                    log_dict = {}\n                    for key, val in avg_meters.items():\n                        if \"Loss/\" in key:\n                            print(f'{key}\\t: {val.avg:2.4f}')\n                            log_dict[key] = val.avg\n                            if log_flag:\n                                self.run.log(\n                                    {f'train/{key}': val.avg}, step=epoch)\n                    print(f'---------------------------------------------------')\n\n                    # Valid\n                    if epoch % self.default_hparams[\"valid_interval\"] == 0:\n                        print(\n                            f'------------- valid epoch: {epoch} ------------------')\n                        self.method = method\n                        _, valid_loss = self.evaluate(\n                            valid=True)  # run_metrics\n\n                        self.es(val_loss=valid_loss)\n\n                        if self.es.early_stop:\n                            print(\"Early stopping\")\n                            break\n\n                self.es.refresh()\n                # Train Done, Test\n                self.method = method\n                metric, _ = self.evaluate()\n                self.metrics[f\"{self.tmp_scenario}_run_{run_id}\"] = metric\n\n            # scenario_run Done\n        # scenario Done\n        self.save_results()\n    # end train\n# end class\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:04:44.642573Z","iopub.execute_input":"2025-05-03T13:04:44.642958Z","iopub.status.idle":"2025-05-03T13:04:44.672986Z","shell.execute_reply.started":"2025-05-03T13:04:44.642920Z","shell.execute_reply":"2025-05-03T13:04:44.672099Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Configs & Main","metadata":{}},{"cell_type":"code","source":"\nimport os\nclass CNN_configs(object):\n    def __init__(self) -> None:\n        super(CNN_configs, self).__init__()\n        self.input_channels = 3  # 模态通道总数\n        self.kernel_size = 5  # 第一层kernel_size\n        self.stride = 1  # 第一层stride\n        self.dropout = 0.5  # 第一层dropout\n\n        self.mid_channels = 64  # 中间通道数\n        self.final_out_channels = 128  # 最后一层输出通道数\n        self.features_len = 1  # avgpool 平均结果长度\n\n\nclass Classifier_configs(object):\n    def __init__(self) -> None:\n        super(Classifier_configs, self).__init__()\n        self.features_len = 1  # CNN avgpool 平均结果长度\n        self.hidden_dim = 500\n        self.final_out_channels = 128  # CNN 最后一层输出通道数\n\n\nclass Discriminator_configs(object):\n    def __init__(self) -> None:\n        super(Discriminator_configs, self).__init__()\n        self.final_out_channels = 128  # CNN最后一层输出通道数\n        self.features_len = 1  # CNN avgpool 平均结果长度\n        self.disc_hid_dim = 64\n\n\nclass fusion_configs(object):\n    def __init__(self) -> None:\n        super(fusion_configs, self).__init__()\n        self.final_out_channels = 128  # cnn_rs.shape[-1]\n        self.hidden_size = 500\n\n\nclass PAMAP2_configs(object):  # HHAR dataset, SAMSUNG device.\n    def __init__(self):\n        super(PAMAP2_configs, self).__init__()\n        self.sequence_len = 200\n        self.num_users = 9  # 1~9\n\n        self.scenarios = [(\"1\", \"7\"), (\"2\", \"5\"), (\"5\", \"7\"),\n                          (\"6\", \"5\"), (\"7\", \"2\")]  # select 5\n        self.num_classes = 18  # 0~17\n        self.class_names = ['lying' 'sitting', 'standing', 'walking', 'running',\n                            'cycling', 'Nordic walking', 'watching TV', 'computer work', 'car driving',\n                            'ascending stairs', 'descending stairs', 'vacuum cleaning', 'ironing', 'folding laundry',\n                            'house cleaning', 'playing soccer', 'rope jumping']\n\n        self.shuffle = True\n        self.drop_last = True\n        self.normalize = True\n        self.modality_nums = 3 * 3  # 传感器模态数\n        self.channel_nums = [3, 3, 3] + [3, 3, 3] + [3, 3, 3]  # 各个模态通道数\n\n        self.model_configs = {\n            'CNN': CNN_configs(),\n            'fusion': fusion_configs(),\n            'Classifier': Classifier_configs(),\n            'Discriminator': Discriminator_configs(),\n        }\n\n\n# -------------------- 训练配置 ---------------------------\nclass PAMAP2_hparams():\n    def __init__(self):\n        super(PAMAP2_hparams, self).__init__()\n        self.train_params = {\n            'num_epochs': 100,  # 总训练轮数\n            'batch_size': 128,  # 每个域的batch数\n            'weight_decay': 1e-4,\n            'valid_interval': 2,\n        }\n        self.alg_hparams = {\n            'ATFA':       {'learning_rate': 0.0005,   'src_cls_loss_wt': 7.737,  'domain_loss_wt': 3.369,  'contrastive_loss_wt': 0.0,  },#'contrastive_loss_wt': 0.5,  # 新增参数\n        }\n\n\nclass args():\n    def __init__(self) -> None:\n        self.method_cls = ATFA\n        self.hparams = PAMAP2_hparams()\n        self.ds_configs = PAMAP2_configs()\n        self.data_path = \"/kaggle/input/pamap2accgyromag/PAMAP2_data\"\n        self.num_runs = 5\n        self.device = \"cuda:0\"\n        self.method_name = \"ATFA\"\n        self.dataset_name = \"PAMAP2\"\n\n\nargs = args()\ntrainer = trainer(args)\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T13:04:44.674368Z","iopub.execute_input":"2025-05-03T13:04:44.674694Z","execution_failed":"2025-05-03T13:05:41.736Z"}},"outputs":[],"execution_count":null}]}